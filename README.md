# README.md for ChessAI

To execute the code go to either `test_chess.py` or `gui_chess.py` and uncomment players and corresponding algorithms you would like. Make sure you have selected one `player1` and one `player2`. 

For `MinimaxAI`, `AlphaBetaAI`, and `IterativeDeepeningMinimaxAI` you can select the max depth you would like the algorithms to traverse each iteration by changing the first argument in the object constructor. The second boolean corresponds to if the player is white or black with `True` corresponding to white and `False` corresponding to black.

This this chess ai implements the standard minimax algorithm, a version that utilized alpha-beta pruning, and a version that utilized iterative deepening to create an actor to play the given chess model using the `python-chess` library from <https://python-chess.readthedocs.io/en/latest/core.html>.

*Minimax:* The minimax algorithm loops through the list of possible moves at the position and then recursively explores the nodes till the max depth and then scores them using max scoring for the player and min scoring for the opponent to derive the optimal move that adheres to the material heuristic as suggested by the book. Minimax loops through the entire tree of possible nodes till the max depth. In addition to the typical implementation, I also added checks to the game cutoff function to avoid moves that resulted in a stalemate and shuffled the dictionary of suggested moves to decrease the chance of move loops. 

*Alpha-Beta Pruning:* The minimax algorithm with alpha-beta pruning implements minimax by looping through the possible moves and recursively deepening, but also compares the scores of nodes those on the same level connected to the same parent node. If the score of a previously visited node on the same level is greater or less (depending on if it is a maximum or minimum node respectively). If the successive, same-depth child score is less than the greatest possible value of the for a max node the the rest of those nodes are pruned and vise versa for a minimum node. 

I also added checking that the current move was not the reverse of the previous one, had checks to the game cutoff function to avoid scenarios that resulted in stalemate scenarios, and shuffled the dictionary of suggested moves to decrease the chance of move loops. With the alpha-beta pruning, I had particular difficulty with avoiding the fivefold repetition condition which is triggered if the position of all the pieces on the board are in the exact same places 5 times in a game. This typically happened if playing in the endgame against minimax of the same depth because whichever ended up with the single piece advantage (if they did not stalemate by insufficient pieces to checkmate) would then attempt to continually check the opposing king limiting its moves to a subsection of the board eventually resulting in five identical situations. Using the cuttoff test in addition to the previous move checker in this way made more of the games end in a conclusion, but also meant that the alpha-beta sometimes ran out of moves in a hopeless situation where the reverse or a cuttoff was the only option, so I also added a random move pick if this was the case to spur the game along. 

*Iterative Deepening Minimax:* Iterative deepening minimax is exactly like minimax, except instead of recusing to the given max depth, iterative deepening minimax calculates a best move at each depth with better moves coming at later depths. The utility is for not having the time to traverse to the max depth, with iterative deepening there will always be a move available and better moves become available as time goes on.  

*Evaluation Function:* For the evaluation function, I implemented the suggested material evaluation heuristic which values pieces based on as point system. Pawns are worth 1 point, bishops and knights 3 points, rooks 5 points, queen's 9 points. I valued the king at 100 points as capturing it is the goal. The players points were added to the score total by looping over every square of the board while the opponents points were subtracted from the total with the goal of maximizing the player's point total. Initial states of the game started at 0 while successive moves that captured opponents' pieces increased the score and losing pieces decreased the score.    
